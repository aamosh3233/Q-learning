{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q_learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GDfKh_nPWas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym,numpy as np\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF7bh4oMP0GK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make('FrozenLake-v0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrI1vJ3AQliQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Agents Q TABLE\n",
        "action=env.action_space.n  #NUMBER OF ACTIONS AGENTS CAN TAKE\n",
        "state=env.observation_space.n   #NUMBER OF STATES WITH AGENTS TAKING ACTIONS\n",
        "q_table=np.zeros((state,action))   #Q TABLE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHZFKf1zTZZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hyper parameters for agents\n",
        "\n",
        "lr=0.01 #learning rate \n",
        "episodes=500\n",
        "explortion_rate=1\n",
        "max_exploration_rate=0.1 \n",
        "min_exploration_rate=0.01\n",
        "decay_exploration=0.001 #exploration needs to be decreased over time\n",
        "discount=0.99 #gamma\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKVjSShLgY6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reward_from_all_episodes=[] # stores all the rewards or scores from each episodes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frMXtmV_iAEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for episode in range (episodes):\n",
        "  \n",
        "  state=env.reset() #reset the environment to start new game\n",
        "  done = False # the game hasnt't started yet so its not done duh :D\n",
        "  rewards=[] # in each episode reward is 0 when game starts \n",
        "  #explore=[]\n",
        "  for step in range(1000): #steps the agents take ie. agent take 1000 step in game\n",
        "    \n",
        "    r=np.random.uniform(0,1) # random number is created\n",
        "    \n",
        "    if r > explortion_rate:\n",
        "      action=env.action_space.sample() # agent explores the environment\n",
        "    else:\n",
        "      action=np.argmax(q_table[state,:]) #checks all the state and takes action\n",
        "    \n",
        "    new_state,reward,done,info=env.step(action) \n",
        "    #formula Bellmans's equation\n",
        "    q_table[state,action]=(1-lr)*q_table[state,action]+lr*(reward+discount*np.max(q_table[new_state,:]))\n",
        "    \n",
        "    #after calculation exploration and action is taken ,, new state is formed\n",
        "    state=new_state #new state\n",
        "    rewards.append(reward) #appending reward (optional)\n",
        "    #explore.append(explortion_rate)\n",
        "    if done ==True:\n",
        "      break\n",
        "  # exploration rate must decay with respect to time i.e formula for exploration decay (dont worry about it)\n",
        "  \n",
        "  explortion_rate=min_exploration_rate+(max_exploration_rate-min_exploration_rate)*np.exp(-decay_exploration*episode)    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epN3Vel2Rtjn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "007a5976-162e-4b28-9218-f84c406f2d72"
      },
      "source": [
        "q_table #got the final q_table"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.09893517e-06, 2.63124515e-06, 2.51909464e-06, 1.97715730e-06],\n",
              "       [1.08921927e-06, 4.37368534e-06, 4.08119967e-06, 5.31069810e-06],\n",
              "       [2.91831185e-05, 1.70038484e-05, 1.93254422e-05, 2.44730243e-06],\n",
              "       [1.21377585e-06, 1.24875241e-06, 1.38958382e-07, 1.00389236e-06],\n",
              "       [4.33338386e-06, 3.11668521e-06, 3.62558352e-06, 8.88144822e-07],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [2.44995231e-04, 1.32151334e-04, 1.35070215e-04, 9.86377145e-07],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.43819383e-06, 2.32195714e-05, 1.81486745e-05, 1.78442739e-05],\n",
              "       [5.20015026e-05, 2.31165936e-04, 1.49403793e-04, 1.18060324e-04],\n",
              "       [3.18603053e-03, 1.44545077e-03, 1.08733251e-03, 1.32541944e-05],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [1.34420778e-05, 8.80074826e-04, 1.29360330e-03, 3.09653007e-03],\n",
              "       [1.55327556e-03, 4.75952116e-02, 5.72991940e-02, 1.86389646e-02],\n",
              "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPqlY7RSTVMv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "65056e6c-ce50-4cfc-c935-bfcfda653fb7"
      },
      "source": [
        "### SEEING THE AGENT PLAY WITHIN THE ENVIRONMENT ###\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "see how the epxloration rate has changed\n",
            "exploratio rate= [0.0915984013378529, 0.0915984013378529, 0.0915984013378529, 0.0915984013378529, 0.0915984013378529]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI5_EVj7Tz7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "461b3682-c4d1-407e-cb4b-bc988466936c"
      },
      "source": [
        "import time\n",
        "for episode in range (3):\n",
        "  \n",
        "  state=env.reset() #reset the environment to start new game\n",
        "  done = False # the game hasnt't started yet so its not done duh :D\n",
        "  \n",
        "  print('*********** EPISODE =',episode,'***********','\\n')\n",
        "  time.sleep(1)\n",
        "  \n",
        "  for step in range(100):\n",
        "    clear_output(wait=True)\n",
        "    env.render()\n",
        "    time.sleep(0.2)\n",
        "    action=np.argmax(q_table[state,:])\n",
        "    new_state,reward,done,info=env.step(action)\n",
        "    \n",
        "    if done:\n",
        "      clear_output(wait=True)\n",
        "      env.render()\n",
        "      if reward == 1:\n",
        "        print('YOU WON CONGRATULATIONS')\n",
        "        time.sleep(3)\n",
        "      else:\n",
        "        print('you lose ,, try agian')\n",
        "        time.sleep(3)\n",
        "        clear_output(wait=True)\n",
        "        break\n",
        "    state=new_state\n",
        "  env.close()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "\u001b[41mH\u001b[0mFFG\n",
            "you lose ,, try agian\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlVgBM8UWonm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBGvGDmhYP_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlarjDQVlHPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}