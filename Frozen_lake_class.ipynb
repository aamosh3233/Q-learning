{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Frozen_lake_class.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGoGFuT2U7FB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym,numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOO4pW9bU-gb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making environment for agent\n",
        "env=gym.make('FrozenLake-v0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7yVw9rBVMSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### MAKING A AGENT TO PLAY IN ENVIRONMENT USING OOP CONCEPTS ######"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67iut20YVz1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent:\n",
        "  def __init__(self):\n",
        "    #hyper parameters\n",
        "    self.lr=0.1\n",
        "    self.epsilon=1\n",
        "    self.max_epsilon=0.1\n",
        "    self.min_epsilon=0.01\n",
        "    self.reward=0.99\n",
        "    self.discount=0.99\n",
        "    self.action=env.action_space.n\n",
        "    self.state=env.observation_space.n\n",
        "    self.q_table=np.zeros((self.state,self.action))\n",
        "    self.episode=500\n",
        "    \n",
        "  \n",
        "  # choosing explore and return new state for agent\n",
        "  def explore(self,state,epsilone): \n",
        "    r=np.random.uniform(0,1)\n",
        "    if r > epsilone :\n",
        "      action=env.action_space.sample()\n",
        "    else:\n",
        "      action=np.argmax(self.q_table[state,:])\n",
        "    new_state,reward,done,info=env.step(action)\n",
        "    return new_state,action,done\n",
        "  \n",
        "  # Q_table is updated here\n",
        "  \n",
        "  def update_q_table(self,state,new_state,new_action):\n",
        "    self.q_table[state,new_action]=self.q_table[state,action]*(1-self.lr)+self.lr*(self.reward+self.discount*np.max(self.q_table[new_state,:]))\n",
        "    return self.q_table\n",
        "  \n",
        "  def decay_explore(self):\n",
        "      epsilon_rate=self.min_epsilon+(self.max_epsilon-self.min_epsilon)*np.exp(-self.discount*self.episode)\n",
        "      return epsilon_rate\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2cg4goKYnSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agent=Agent()\n",
        "epsilon=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3ukwHTxaDsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for episode in range(500):\n",
        "  done=False\n",
        "  state=env.reset()\n",
        "  for step in range(1000):\n",
        "    new_state,action,done = agent.explore(state,epsilon)\n",
        "    q_table = agent.update_q_table(state,new_state,action)\n",
        "    state=new_state\n",
        "    if done == True:\n",
        "      break\n",
        "  epsilon=agent.decay_explore()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLVEkkNbezNJ",
        "colab_type": "code",
        "outputId": "8193166e-258a-4516-8ac5-db99e70aad88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "q_table"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[13.96680554, 13.59035734, 14.24058567, 15.34551328],\n",
              "       [ 9.75755679,  8.35626974,  8.64928752, 13.65162938],\n",
              "       [10.58153549,  8.40628926,  6.04762077, 10.31142326],\n",
              "       [ 4.04740896,  4.31341457,  3.81459948,  5.7590475 ],\n",
              "       [12.10804576,  6.55724134,  8.36731578,  8.7214045 ],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 3.13172934,  1.26339854,  2.69235505,  2.46639855],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 5.99628217,  4.18618402,  5.73558236,  7.8937399 ],\n",
              "       [ 2.7408016 ,  2.29249069,  1.2311238 ,  2.79734307],\n",
              "       [ 2.1063884 ,  0.81558539,  1.20098187,  1.86539474],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 1.12089471,  0.93503986,  1.08148523,  0.83857168],\n",
              "       [ 1.00817699,  0.7838052 ,  0.9221707 ,  0.52991123],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1wDrk-RgVnU",
        "colab_type": "code",
        "outputId": "813ba8cb-a70f-461b-f207-b06241ab9d01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import time\n",
        "from IPython.display import clear_output\n",
        "for episode in range (2):\n",
        "  \n",
        "  state=env.reset() #reset the environment to start new game\n",
        "  done = False # the game hasnt't started yet so its not done duh :D\n",
        "  \n",
        "  print('*********** EPISODE =',episode,'***********','\\n')\n",
        "  time.sleep(1)\n",
        "  \n",
        "  for step in range(100):\n",
        "    clear_output(wait=True)\n",
        "    env.render()\n",
        "    time.sleep(0.2)\n",
        "    action=np.argmax(q_table[state,:])\n",
        "    new_state,reward,done,info=env.step(action)\n",
        "    \n",
        "    if done:\n",
        "      clear_output(wait=True)\n",
        "      env.render()\n",
        "      if reward == 1:\n",
        "        print('YOU WON CONGRATULATIONS')\n",
        "        time.sleep(1)\n",
        "      else:\n",
        "        print('you lose ,, try agian')\n",
        "        time.sleep(1)\n",
        "        clear_output(wait=True)\n",
        "        break\n",
        "    state=new_state\n",
        "  env.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (Left)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "you lose ,, try agian\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZJ7wlZCh3Ce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}